{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58f7577d-6516-4e7a-81a1-1e3614821255",
   "metadata": {},
   "source": [
    "# <center>INFO557: Final Project\n",
    "### <center>Namig Abbasov "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506a3fe8-4818-4c2a-af9c-195250300de9",
   "metadata": {},
   "source": [
    "## Import Libraries and Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be217306-e34a-485b-9618-a8e7f5219e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/namigabbasov/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input,Embedding, Bidirectional, LSTM, Dense, Dropout, BatchNormalization, GlobalMaxPooling1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76ce08e3-6b57-44a9-8b9f-49d9d13b4e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "dev_df = pd.read_csv(\"dev.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cb4bf2-d8ad-4160-8318-c04c7ea14574",
   "metadata": {},
   "source": [
    "## Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5e0372a-77da-4550-8619-8d12debbe8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### reproducibility\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee07d8c6-35d2-4cce-8b17-d4c4bcb8fce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### prepare labels and train and dev sets \n",
    "\n",
    "label_cols = [\"admiration\", \"amusement\", \"gratitude\", \"love\", \"pride\", \"relief\", \"remorse\"]\n",
    "X_train_text = train_df[\"text\"].astype(str)\n",
    "y_train = train_df[label_cols].values\n",
    "X_dev_text = dev_df[\"text\"].astype(str)\n",
    "y_dev = dev_df[label_cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7febec51-94fe-45ba-8b3d-e231d6a8e194",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tokenization\n",
    "\n",
    "vocab_size = 20000\n",
    "max_len = 120\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train_text)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "X_train = pad_sequences(tokenizer.texts_to_sequences(X_train_text), maxlen=max_len)\n",
    "X_dev = pad_sequences(tokenizer.texts_to_sequences(X_dev_text), maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37baea7f-40ca-4fc5-a4bb-657205f25fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load GloVe and build embedding matrix to initialize weights in neural network\n",
    "\n",
    "embedding_index = {}\n",
    "with open(\"glove.6B.100d.txt\", encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        values = line.strip().split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], dtype='float32')\n",
    "        embedding_index[word] = vector\n",
    "\n",
    "embedding_dim = 100\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i < vocab_size:\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857362d5-b870-4dca-b724-bfc485eda769",
   "metadata": {},
   "source": [
    "## Model Development, Training, and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffead0fa-bc43-492f-a816-18f360bf8222",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/namigabbasov/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "2025-05-05 00:14:51.350561: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Max\n",
      "2025-05-05 00:14:51.350652: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 36.00 GB\n",
      "2025-05-05 00:14:51.350669: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 13.50 GB\n",
      "2025-05-05 00:14:51.350702: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-05-05 00:14:51.350729: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "### Build Model \n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix],\n",
    "                  input_length=max_len, trainable=True),  \n",
    "        Bidirectional(LSTM(64, return_sequences=True)),\n",
    "        GlobalMaxPooling1D(),  \n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(len(label_cols), activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd665f0e-5722-45be-8517-1a90f2756f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Early stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb65f86-9617-48df-bf2d-300fec6bd5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 00:14:53.873667: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m788/788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 180ms/step - accuracy: 0.4715 - loss: 0.2509 - val_accuracy: 0.4290 - val_loss: 0.0860\n",
      "Epoch 2/15\n",
      "\u001b[1m788/788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 180ms/step - accuracy: 0.6392 - loss: 0.0963 - val_accuracy: 0.6269 - val_loss: 0.0698\n",
      "Epoch 3/15\n",
      "\u001b[1m788/788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 192ms/step - accuracy: 0.6349 - loss: 0.0829 - val_accuracy: 0.6034 - val_loss: 0.0681\n",
      "Epoch 4/15\n",
      "\u001b[1m788/788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 193ms/step - accuracy: 0.6138 - loss: 0.0733 - val_accuracy: 0.5481 - val_loss: 0.0688\n",
      "Epoch 5/15\n",
      "\u001b[1m547/788\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m45s\u001b[0m 187ms/step - accuracy: 0.6015 - loss: 0.0658"
     ]
    }
   ],
   "source": [
    "### train model\n",
    "model.fit(X_train, y_train, epochs=15, batch_size=32,\n",
    "          validation_data=(X_dev, y_dev), callbacks=[early_stop], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373e3cce-80ec-45fa-a9bb-aa7fb731da20",
   "metadata": {},
   "outputs": [],
   "source": [
    "### predict on dev\n",
    "dev_probs = model.predict(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805f4182-d683-4f1e-af62-3c32a40bb2c2",
   "metadata": {},
   "source": [
    "## Threshold Tuning as Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10e633b-a623-4bb4-86d7-78c076d03684",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_f1 = 0\n",
    "best_thresh = 0.5\n",
    "\n",
    "for t in np.arange(0.3, 0.6, 0.02):\n",
    "    dev_preds = (dev_probs > t).astype(int)\n",
    "    f1 = f1_score(y_dev, dev_preds, average='micro')\n",
    "    print(f\"Threshold {t:.2f} → Micro F1: {f1:.4f}\")\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_thresh = t\n",
    "\n",
    "print(f\"\\nBest threshold: {best_thresh:.2f} with Micro F1: {best_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae40a0d0-5ba2-419d-b717-c8875a052359",
   "metadata": {},
   "source": [
    "## Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82474a1d-ff79-4177-a8d9-efa494b30a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = (dev_probs > best_thresh).astype(int)\n",
    "dev_submission = dev_df[[\"text\"]].copy()\n",
    "dev_submission[label_cols] = final_preds\n",
    "dev_submission.to_csv(\"submission_dev.csv\", index=False)\n",
    "\n",
    "with zipfile.ZipFile(\"submission_dev.zip\", 'w') as zipf:\n",
    "    zipf.write(\"submission_dev.csv\")\n",
    "print(\"Dev submission saved as submission_dev.zip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
